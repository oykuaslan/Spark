{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+---+--------------------+--------+\n",
      "|      Date|Latitude|Longitude| xM|            Location|  Region|\n",
      "+----------+--------+---------+---+--------------------+--------+\n",
      "|2020.12.31| 37.8435|  26.7775|3.8|          EGE DENIZI|Region 5|\n",
      "|2020.12.30| 36.4918|  28.7092|3.9|             AKDENIZ|Region 5|\n",
      "|2020.12.30|  37.796|  26.4165|4.4|ONIKI ADALAR (AKD...|Region 5|\n",
      "|2020.12.27| 38.4172|  39.1482|3.9|KAVAKKOY-SIVRICE ...|Region 7|\n",
      "|2020.12.27|  36.475|  28.7852|4.2|             AKDENIZ|Region 5|\n",
      "|2020.12.27|  38.505|   39.218|5.6|KAVAKTEPE- (ELAZI...|Region 7|\n",
      "|2020.12.26| 38.5305|  39.2102|4.1|KAVAKTEPE- (ELAZI...|Region 7|\n",
      "|2020.12.26| 38.0033|  42.9642|3.9|KORULU-CATAK (VAN...|Region 8|\n",
      "|2020.12.23| 36.5213|   28.695|3.7|             AKDENIZ|Region 5|\n",
      "|2020.12.23| 37.8888|  27.6075|3.7|DAGKARAAGAC-GERME...|Region 5|\n",
      "|2020.12.22| 35.7737|   36.447|3.9|              SURIYE|Region 7|\n",
      "|2020.12.20| 37.8967|  43.8062|4.5|AYDEMIR-BASKALE (...|Region 8|\n",
      "|2020.12.20|  37.126|  28.5738|4.0|ARICILAR-ULA (MUG...|Region 5|\n",
      "|2020.12.18| 37.1175|  31.0832|3.7|ETLER-SERIK (ANTA...|Region 6|\n",
      "|2020.12.18| 35.7012|  26.2608|3.6|             AKDENIZ|Region 5|\n",
      "|2020.12.17| 35.7032|  26.2382|4.6|             AKDENIZ|Region 5|\n",
      "|2020.12.15|  35.704|  26.2952|3.8|             AKDENIZ|Region 5|\n",
      "|2020.12.15|  35.691|  26.2818|3.9|             AKDENIZ|Region 5|\n",
      "|2020.12.14| 38.8573|  43.5082|4.7|ERMISLER- (VAN) [...|Region 8|\n",
      "|2020.12.13|  37.683|  27.0502|3.5|MILLI PARK-KUSADA...|Region 5|\n",
      "+----------+--------+---------+---+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+-----+\n",
      "|  Region|count|\n",
      "+--------+-----+\n",
      "|Region 5| 7946|\n",
      "|Region 1| 2827|\n",
      "|Region 8| 1547|\n",
      "|Region 7| 1335|\n",
      "|Region 6| 1277|\n",
      "|Region 2|  994|\n",
      "|Region 3|  982|\n",
      "|Region 4|  752|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SparkDF USer Defined Functions\").getOrCreate()\n",
    "\n",
    "earthquakeDF= spark.read.option(\"header\",\"true\")\\\n",
    "                        .option(\"delimiter\",\"\\t\")\\\n",
    "                        .option(\"inferSchema\",\"True\")\\\n",
    "                        .csv(\"datasets/EarthquakeDataset.txt\")\n",
    "\n",
    "earthquakeDF = earthquakeDF.select(\"Date\",\"Latitude\",\"Longitude\",\"xM\",\"Location\")\n",
    "#earthquakeDF.show()\n",
    "\n",
    "def assingRegion(lat,lng):\n",
    "    region = \"\"\n",
    "    if lat >= 39:\n",
    "        if lng <= 31:\n",
    "            region =\"Region 1\"\n",
    "        elif lng <= 36:\n",
    "            region =\"Region 2\"        \n",
    "        elif lng <= 41:\n",
    "            region =\"Region 3\"\n",
    "        else:\n",
    "            region =\"Region 4\"\n",
    "    else:\n",
    "        if lng <= 31:\n",
    "            region =\"Region 5\"\n",
    "        elif lng <= 36:\n",
    "            region =\"Region 6\"        \n",
    "        elif lng <= 41:\n",
    "            region =\"Region 7\"\n",
    "        else:\n",
    "            region =\"Region 8\"         \n",
    "    return  region\n",
    "\n",
    "assingUDF = UserDefinedFunction(assingRegion,StringType())\n",
    "earthquakeDF  = earthquakeDF.withColumn(\"Region\",assingUDF(\"Latitude\",\"Longitude\"))\n",
    "earthquakeDF.show()\n",
    "regionDF = earthquakeDF.groupBy(\"Region\").count()\n",
    "regionDF.createOrReplaceTempView(\"region\")\n",
    "#spark.sql(\"select Region, count from region order by count desc\").show()\n",
    "regionDF.sort(\"count\",ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
