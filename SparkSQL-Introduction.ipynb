{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+---+--------------------+\n",
      "|      Date|Latitude|Longitude| xM|            Location|\n",
      "+----------+--------+---------+---+--------------------+\n",
      "|2020.12.31| 37.8435|  26.7775|3.8|          EGE DENIZI|\n",
      "|2020.12.30| 36.4918|  28.7092|3.9|             AKDENIZ|\n",
      "|2020.12.30| 37.7960|  26.4165|4.4|ONIKI ADALAR (AKD...|\n",
      "|2020.12.27| 38.4172|  39.1482|3.9|KAVAKKOY-SIVRICE ...|\n",
      "|2020.12.27| 36.4750|  28.7852|4.2|             AKDENIZ|\n",
      "|2020.12.27| 38.5050|  39.2180|5.6|KAVAKTEPE- (ELAZI...|\n",
      "|2020.12.26| 38.5305|  39.2102|4.1|KAVAKTEPE- (ELAZI...|\n",
      "|2020.12.26| 38.0033|  42.9642|3.9|KORULU-CATAK (VAN...|\n",
      "|2020.12.23| 36.5213|  28.6950|3.7|             AKDENIZ|\n",
      "|2020.12.23| 37.8888|  27.6075|3.7|DAGKARAAGAC-GERME...|\n",
      "|2020.12.22| 35.7737|  36.4470|3.9|              SURIYE|\n",
      "|2020.12.20| 37.8967|  43.8062|4.5|AYDEMIR-BASKALE (...|\n",
      "|2020.12.20| 37.1260|  28.5738|4.0|ARICILAR-ULA (MUG...|\n",
      "|2020.12.18| 37.1175|  31.0832|3.7|ETLER-SERIK (ANTA...|\n",
      "|2020.12.18| 35.7012|  26.2608|3.6|             AKDENIZ|\n",
      "|2020.12.17| 35.7032|  26.2382|4.6|             AKDENIZ|\n",
      "|2020.12.15| 35.7040|  26.2952|3.8|             AKDENIZ|\n",
      "|2020.12.15| 35.6910|  26.2818|3.9|             AKDENIZ|\n",
      "|2020.12.14| 38.8573|  43.5082|4.7|ERMISLER- (VAN) [...|\n",
      "|2020.12.13| 37.6830|  27.0502|3.5|MILLI PARK-KUSADA...|\n",
      "+----------+--------+---------+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession #DataFrame object will be created using SparkSessio\n",
    "spark = SparkSession.builder.appName(\"Spark Dataframe Intro\").getOrCreate()\n",
    "from pyspark.sql import SparkSession #DataFrame object will be created using SparkSessio\n",
    "spark = SparkSession.builder.appName(\"Spark Dataframe Intro\").getOrCreate()\n",
    "\n",
    "earthquakeDF= spark.read.option(\"header\",\"true\")\\\n",
    "                        .option(\"delimiter\",\"\\t\")\\\n",
    "                        .csv(\"datasets/EarthquakeDataset.txt\")\n",
    "earthquakeDF = earthquakeDF.select(\"Date\",\"Latitude\",\"Longitude\",\"xM\",\"Location\")\n",
    "earthquakeDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+---+--------------------+\n",
      "|      Date|Latitude|Longitude| xM|            Location|\n",
      "+----------+--------+---------+---+--------------------+\n",
      "|1939.12.26| 39.8000|  39.5100|7.9|KURUTILEK- (ERZIN...|\n",
      "|1926.06.26| 36.5400|  27.3300|7.7|ONIKI ADALAR (AKD...|\n",
      "|1930.05.06| 37.9800|  44.4800|7.6|T�RKIYE-IRAN SINI...|\n",
      "|1976.11.24| 39.0500|  44.0400|7.5|YENIYAKA-CALDIRAN...|\n",
      "|1999.08.17| 40.7600|  29.9700|7.4|BASISKELE (KOCAEL...|\n",
      "|1912.08.09| 40.6000|  27.2000|7.3|ERIKLICE-SARKOY (...|\n",
      "|1999.11.12| 40.7400|  31.2100|7.2|UGUR- (DUZCE) [No...|\n",
      "|1953.03.18| 39.9900|  27.3600|7.2|SOGUCAK-YENICE (�...|\n",
      "|1948.02.09| 35.4100|  27.2000|7.2|             AKDENIZ|\n",
      "|1943.11.26| 41.0500|  33.7200|7.2|COMERT-ILGAZ (�AN...|\n",
      "|1944.02.01| 40.7871|  31.8723|7.2|    ULUMESCIT-(BOLU)|\n",
      "|2011.10.23| 38.7212|  43.4110|7.2|YEMLICE- (VAN) [N...|\n",
      "|1957.05.26| 40.6700|  31.0000|7.1|GUZELDERE-GOLYAKA...|\n",
      "|1957.04.25| 36.4200|  28.6800|7.1|             AKDENIZ|\n",
      "|1916.01.24| 40.2700|  36.8300|7.1|TEKNECIK-ALMUS (T...|\n",
      "+----------+--------+---------+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SparkSQL  -- can be used for ETL (Extract, Transform, Load operations)\n",
    "earthquakeDF.createOrReplaceTempView(\"earthquake\") # Registering Dataframe as a View\n",
    "resultDF = spark.sql(\"select * from  earthquake where xM>7.0 order by xM desc\")\n",
    "resultDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDF.coalesce(1).write.option(\"header\", \"true\").option(\"sep\",\"\\t\").csv(\"sample_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
