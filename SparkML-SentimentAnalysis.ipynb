{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                 _c0|_c1|\n",
      "+--------------------+---+\n",
      "|bunu da gördük uz...|  0|\n",
      "|filmi begenmeyenl...|  0|\n",
      "|günde 1 film izle...|  0|\n",
      "|afisine bakip ald...|  0|\n",
      "|sadece insanlarin...|  0|\n",
      "|ucuz bir aksiyon ...|  0|\n",
      "|olmamis diyor pua...|  0|\n",
      "|kesinlikle çok kö...|  0|\n",
      "|ben nasil bir fil...|  0|\n",
      "|bu yüzler fazla t...|  0|\n",
      "|. çok ilginç yaa ...|  0|\n",
      "|bence bu film hiç...|  0|\n",
      "|valla ben begenme...|  0|\n",
      "|gönül ister milyo...|  0|\n",
      "|dün aksam bu film...|  0|\n",
      "|cok kötü olmus......|  0|\n",
      "|igrenç yaaa.acaba...|  0|\n",
      "|saçma sapan bir f...|  0|\n",
      "|çok güzel komedi ...|  0|\n",
      "|beklentimi yüksek...|  0|\n",
      "+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|               tweet|label|              tokens|       no-stop-words|            features|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|bunu da gördük uz...|    0|[bunu, da, gördük...|[bunu, da, gördük...|(7538,[14,16,27,1...|\n",
      "|filmi begenmeyenl...|    0|[filmi, begenmeye...|[filmi, begenmeye...|(7538,[0,1,5,6,50...|\n",
      "|günde 1 film izle...|    0|[günde, 1, film, ...|[günde, 1, film, ...|(7538,[0,1,4,11,2...|\n",
      "|afisine bakip ald...|    0|[afisine, bakip, ...|[afisine, bakip, ...|(7538,[2,3,4,13,3...|\n",
      "|sadece insanlarin...|    0|[sadece, insanlar...|[sadece, insanlar...|(7538,[0,1,14,17,...|\n",
      "|ucuz bir aksiyon ...|    0|[ucuz, bir, aksiy...|[ucuz, bir, aksiy...|(7538,[0,3,5,36,4...|\n",
      "|olmamis diyor pua...|    0|[olmamis, diyor, ...|[olmamis, diyor, ...|(7538,[12,178,510...|\n",
      "|kesinlikle çok kö...|    0|[kesinlikle, çok,...|[kesinlikle, çok,...|(7538,[0,1,2,7,21...|\n",
      "|ben nasil bir fil...|    0|[ben, nasil, bir,...|[ben, nasil, bir,...|(7538,[0,1,6,16,2...|\n",
      "|bu yüzler fazla t...|    0|[bu, yüzler, fazl...|[bu, yüzler, fazl...|(7538,[3,4,14,17,...|\n",
      "|. çok ilginç yaa ...|    0|[., çok, ilginç, ...|[., çok, ilginç, ...|(7538,[0,1,2,9,12...|\n",
      "|bence bu film hiç...|    0|[bence, bu, film,...|[bence, bu, film,...|(7538,[1,3,6,8,9,...|\n",
      "|valla ben begenme...|    0|[valla, ben, bege...|[valla, ben, bege...|(7538,[0,2,29,38,...|\n",
      "|gönül ister milyo...|    0|[gönül, ister, mi...|[gönül, ister, mi...|(7538,[3,6,21,24,...|\n",
      "|dün aksam bu film...|    0|[dün, aksam, bu, ...|[dün, aksam, bu, ...|(7538,[3,30,38,49...|\n",
      "|cok kötü olmus......|    0|[cok, kötü, olmus...|[cok, kötü, olmus...|(7538,[7,19,27,32...|\n",
      "|igrenç yaaa.acaba...|    0|[igrenç, yaaa.aca...|[igrenç, yaaa.aca...|(7538,[0,1,3,5,17...|\n",
      "|saçma sapan bir f...|    0|[saçma, sapan, bi...|[saçma, sapan, bi...|(7538,[0,3,11,30,...|\n",
      "|çok güzel komedi ...|    0|[çok, güzel, kome...|[çok, güzel, kome...|(7538,[2,5,8,27,1...|\n",
      "|beklentimi yüksek...|    0|[beklentimi, yüks...|[beklentimi, yüks...|(7538,[0,5,35,59,...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "from pyspark.ml.feature import CountVectorizer,Tokenizer,StopWordsRemover\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SparkML Depression Analysis\").getOrCreate()\n",
    "dataDF= spark.read.option(\"inferSchema\",\"True\")\\\n",
    "                        .option(\"delimiter\",\"\\t\")\\\n",
    "                        .csv(\"datasets/movie_turkish_train.txt\")\n",
    "dataDF.show()\n",
    "dataDF = dataDF.withColumnRenamed(\"_c0\",\"tweet\")\n",
    "\n",
    "dataDF = dataDF.withColumnRenamed(\"_c1\",\"label\")\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='tweet',outputCol='tokens')\n",
    "dataDF = tokenizer.transform(dataDF)\n",
    "\n",
    "remover = StopWordsRemover(inputCol='tokens',outputCol='no-stop-words')\n",
    "dataDF = remover.transform(dataDF)\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(inputCol='no-stop-words',outputCol='features')\n",
    "dataDF = vectorizer.fit(dataDF).transform(dataDF)\n",
    "dataDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(7538,[14,16,27,1...|    0|\n",
      "|(7538,[0,1,5,6,50...|    0|\n",
      "|(7538,[0,1,4,11,2...|    0|\n",
      "|(7538,[2,3,4,13,3...|    0|\n",
      "|(7538,[0,1,14,17,...|    0|\n",
      "|(7538,[0,3,5,36,4...|    0|\n",
      "|(7538,[12,178,510...|    0|\n",
      "|(7538,[0,1,2,7,21...|    0|\n",
      "|(7538,[0,1,6,16,2...|    0|\n",
      "|(7538,[3,4,14,17,...|    0|\n",
      "|(7538,[0,1,2,9,12...|    0|\n",
      "|(7538,[1,3,6,8,9,...|    0|\n",
      "|(7538,[0,2,29,38,...|    0|\n",
      "|(7538,[3,6,21,24,...|    0|\n",
      "|(7538,[3,30,38,49...|    0|\n",
      "|(7538,[7,19,27,32...|    0|\n",
      "|(7538,[0,1,3,5,17...|    0|\n",
      "|(7538,[0,3,11,30,...|    0|\n",
      "|(7538,[2,5,8,27,1...|    0|\n",
      "|(7538,[0,5,35,59,...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n",
      "Test Accuracy :  0.78515625\n"
     ]
    }
   ],
   "source": [
    "dataDF = dataDF.select('features','label')\n",
    "dataDF.show()\n",
    "\n",
    "dataDF.printSchema()\n",
    "\n",
    "trainDF,testDF = dataDF.randomSplit([0.75,0.25])\n",
    "\n",
    "\n",
    "mlpClassifier = MultilayerPerceptronClassifier(layers=[7538,2,2])\n",
    "model = mlpClassifier.fit(trainDF)\n",
    "\n",
    "\n",
    "resultDF = model.transform(testDF) #Prediction\n",
    "#resultDF.show(100)\n",
    "\n",
    "eva = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "accuracy = eva.evaluate(resultDF)\n",
    "print(\"Test Accuracy : \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
